<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="simple.css" rel="stylesheet">
    <title>Erkundungen zu KI</title>
  </head>
  <body>

  <header>
    <h1>Erkundungen zu K√ºnstlicher Intelligenz (KI)</h1>
    <p>Stationen zum individuellen oder gemeinsamen Erkunden</p>
    <nav>
      <ul>
        <li><a href="index.html">√úberblick</a></li>
      </ul>
    </nav>
  </header>

  <main>
   <h2>Station 8: Bias und KI</h2>
    
    <h3>Worum geht es hier?</h3>
    <p>KI-generierte Inhalte sind zwangsl√§ufig immer Bias-behaftet, denn KI-Tools reproduzieren die Vergangenheit, weil sie auf einer Datenbasis aus der Vergangenheit stammen. Stereotype, Diskriminierungen und Vorurteile, die es in den letzten Jahrzehnten in unserer Gesellschaft gab und weiterhin gibt, finden sich vor diesem Hintergrund in den Trainingsdaten und damit auch im Output der vorherrschenden KI-Tools wieder. Wer mit KI-Tools arbeitet, muss dazu einen Umgang finden.</p>

    <h3>Was k√∂nnen wir nutzen?</h3>
    <p>Um sich Bias in KI bewusst zu machen, sind Bildgenerierungstools ein guter Einstieg zum Erkunden. Du kannst zum Beispiel den Prompt nutzen: Eine Person, die auf einer Konferenz redet. Wahrscheinlich wirst du in diesem Fall √ºberwiegend Bilder von wei√üen, redenden M√§nnern erhalten. Denn das sind die Personen, die es in den Trainingsdaten √ºberwiegend redend auf Konferenzen gibt.</p>
    <p>Wir haben aber nat√ºrlich den Anspruch, dass auch Frauen, Schwarze Menschen oder Menschen im Rollstuhl redende Personen auf einer Konferenz sein sollten. Und wir m√∂chten gerne, dass dieses Ziel (was oft ja auch schon eine reale M√∂glichkeit ist) in Bildern entsprechend dargestellt wird, um z.B. auch entsprechende Vorbilder zu bieten.</p>
    <p>Der einfachste Umgang mit dieser Schwierigkeit ist deshalb, in den Eingaben gezielt auf Vielfalt hinzuwirken, z.B. in dem ich in dem Beispiel schreiben w√ºrde: eine Schwarze Frau, die auf einer Konferenz redet. Oft hilft auch der Beisatz 'divers'.</p>
    <p>Alle Probleme sind damit aber nicht gel√∂st, denn manchmal gibt es in den Trainingsdaten schlichtweg so wenig Inhalte, dass trotz entsprechendem Prompting das KI-Modell auf die Mehrheits-Darstellung zur√ºckf√§llt. Diese Herausforderung habe ich im Blogbeitrag <a href="https://ebildungslabor.de/blog/besseres-prompting-hilft-nur-bedingt-gegen-bias/" target="_blank">Besseres Prompting hilft nur bedingt gegen Bias</a> vorgestellt.</p>

    <h3>Wie k√∂nnen wir vorgehen?</h3>
    <p>Macht eigene Erkundungen zu KI und Bias. In Sprachmodellen k√∂nnt ihr z.B. beobachten, mit welchen Eigenschaften Frauen und mit welchen Eigenschaften M√§nner in Texten √ºberwiegend dargestellt werden. All das geschieht sehr subtil. Der erste Schritt zur Ver√§nderung ist ein bewusster Umgang damit. Eine abschlie√üende L√∂sung gibt es zu dieser Herausforderung nicht.</p>

    <p>Viel Erfolg bei der kritischen Auseinandersetzung mit Bias und KI! üôÇ</p>
    

       <p><a href="index.html"><button>> Zur √úbersicht der Stationen</button></a></p>

  </main>

  <footer>
    <p>Verantwortlich f√ºr diese Website ist Nele Hirsch (<a href="https://ebildungslabor.de">eBildungslabor</a>)</p>
    <p>Die Inhalte bleiben auch nach Ablauf unserer Veranstaltung online und k√∂nnen gerne weiter genutzt werden.</p>
  </footer>

  </body>
</html>
